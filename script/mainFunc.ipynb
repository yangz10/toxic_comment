{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Embedding\n",
    "import scipy.sparse\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    train = pd.read_csv('../output/train_pre.csv')\n",
    "    test = pd.read_csv('../output/test_pre.csv')\n",
    "    return train,test\n",
    "\n",
    "def getFeature(Name,CharFlag=False):\n",
    "    \n",
    "    if CharFlag:\n",
    "        train_features = scipy.sparse.load_npz('../output/train_features.npz')\n",
    "        test_features = scipy.sparse.load_npz('../output/test_features.npz')\n",
    "        return train_featuress.todense(),test_features.todense()\n",
    "    else :\n",
    "        if name == 'fastEeb':\n",
    "            fastEeb = np.load('../output/embedMatrix.npy',encoding='latin1')\n",
    "            return fastEeb\n",
    "        else : \n",
    "            globeEbd = np.load('../output/embedMatrixglove.npy',encoding='latin1')\n",
    "            return globeEbd\n",
    "\n",
    "def getSequence():\n",
    "    train_sequence = np.load('../output/x_train_seq.npy',encoding='latin1')\n",
    "    test_sequence = np.load('../output/x_test_seq.npy',encoding='latin1')\n",
    "    return train_sequence,test_sequence\n",
    "\n",
    "def getIP(train,test):\n",
    "    train_ip = train[['ip_0','ip_1', 'ip_2', 'ip_3']]\n",
    "    train_ip['index'] = 1\n",
    "    test_ip = test[['ip_0','ip_1', 'ip_2', 'ip_3']]\n",
    "    test_ip['index'] = 0\n",
    "    result = pd.concat([train_ip,test_ip])\n",
    "\n",
    "    result = pd.get_dummies(result, prefix=['ip_0','ip_1', 'ip_2', 'ip_3'], columns=['ip_0','ip_1', 'ip_2', 'ip_3'],drop_first=True)\n",
    "    train_ip = result[result['index']==1]\n",
    "    test_ip = result[result['index']==0]\n",
    "    return train_ip,test_ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage\n",
    "\n",
    "``` python\n",
    "train,test = getData()\n",
    "train_features,test_features = getFeature('',CharFlag=True)\n",
    "train_sequence,test_sequence = getSequence()\n",
    "train_ip,test_ip = getIP(train,test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xCol = ['ip_0','ip_1', 'ip_2', 'ip_3','caps_vs_length',\n",
    "          'num_punctuation', 'num_unique_words','num_exclamation_marks']\n",
    "yCol = ['toxic','severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "allCol = xCol+yCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[xCol][:1000]\n",
    "y_train = train[yCol][:1000]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_sequence\n",
    "y_train = train[yCol]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(X_train, X_test, y_train, y_test):\n",
    "    n_x,n_m = X_train.shape\n",
    "    n_y = y_test.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_x, activation='relu', input_dim=n_m))\n",
    "    model.add(Dense(n_y, activation='softmax'))\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=3, batch_size=256)\n",
    "    model.evaluate(X_test,y_test,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM01():\n",
    "    # Embedding\n",
    "    max_features = 20000\n",
    "    maxlen = 150\n",
    "    embedding_size = 128\n",
    "\n",
    "    # Convolution\n",
    "    kernel_size = 5\n",
    "    filters = 64\n",
    "    pool_size = 4\n",
    "\n",
    "    # LSTM\n",
    "    lstm_output_size = 70\n",
    "\n",
    "    # Training\n",
    "    batch_size = 128\n",
    "    epochs = 8\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(filters,\n",
    "                     kernel_size,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    model.add(LSTM(lstm_output_size))\n",
    "    model.add(Dense(6))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print('Train...')\n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(X_test, y_test))\n",
    "    score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    model.save_weights(\"LSTM01.h5\")\n",
    "    predict(LSTM01,model,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(name,model,testSet):\n",
    "    y_pred = model.predict(testSet, batch_size=1024, verbose=1)\n",
    "    submission = pd.read_csv('../input/sample_submission.csv')\n",
    "    submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\n",
    "    submission.to_csv('LSTM01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test, batch_size=1024, verbose=1)\n",
    "\n",
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "model.save_weights('best.hdf5')\n",
    "model.save_weights(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
